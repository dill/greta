% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimisers.R
\name{optimisers}
\alias{optimisers}
\alias{adagrad}
\alias{bfgs}
\title{optimisation methods}
\usage{
adagrad(learning_rate = 0.8, initial_accumulator_value = 0.1)

bfgs()
}
\arguments{
\item{learning_rate}{the size of steps (in parameter space) towards the
optimal value}

\item{initial_accumulator_value}{initial value of the 'accumulator' used to
tune the algorithm}
}
\value{
an \code{optimiser} object that can be passed to \code{\link{mcmc}}.
}
\description{
Functions to set up optimisers (which find parameters that
  maximise the joint density of a model) and change their tuning parameters,
  for use in \code{\link{opt}()}.
}
